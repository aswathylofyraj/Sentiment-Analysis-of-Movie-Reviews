# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uK5YHwLeGLHZOKPzwMM7UXumezWMxAj8
"""

import sqlite3
import pandas as pd
from tensorflow.keras.datasets import imdb

# Load the IMDb dataset
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

# Decode reviews (turning integers into words)
word_index = imdb.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
decode_review = lambda review: ' '.join([reverse_word_index.get(i - 3, '?') for i in review])

# Convert to a dataframe
train_df = pd.DataFrame({'review_text': [decode_review(review) for review in train_data], 'label': train_labels})
test_df = pd.DataFrame({'review_text': [decode_review(review) for review in test_data], 'label': test_labels})

# Connect to SQLite and store data
conn = sqlite3.connect('reviews.db')
train_df.to_sql('movie_reviews', conn, if_exists='replace', index=False)
conn.commit()
conn.close()

conn = sqlite3.connect('reviews.db')
train_df = pd.read_sql('SELECT * FROM movie_reviews', conn)
conn.close()

# Tokenization and Padding
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Tokenizing the data
tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(train_df['review_text'])
sequences = tokenizer.texts_to_sequences(train_df['review_text'])
data = pad_sequences(sequences, maxlen=256)

# Labels
labels = train_df['label'].values

from tensorflow.keras import models, layers

# Model architecture
model = models.Sequential()
model.add(layers.Embedding(10000, 16))
model.add(layers.GlobalAveragePooling1D())
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(data, labels, epochs=10, batch_size=512, validation_split=0.2)

import matplotlib.pyplot as plt

# Plot training and validation accuracy
history = model.history.history

plt.plot(history['accuracy'], label='Training accuracy')
plt.plot(history['val_accuracy'], label='Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Load test data from the SQL database (similar to train data)
conn = sqlite3.connect('reviews.db')
# Use the test_df created earlier instead of querying the database
test_df = pd.read_sql('SELECT * FROM movie_reviews', conn)
conn.close()

# Tokenize and pad test data
test_sequences = tokenizer.texts_to_sequences(test_df['review_text'])
test_data = pad_sequences(test_sequences, maxlen=256)
test_labels = test_df['label'].values

# Evaluate the model
test_loss, test_acc = model.evaluate(test_data, test_labels)
print(f'Test accuracy: {test_acc:.4f}')

# Make predictions
predictions = model.predict(test_data)

# Print some sample predictions with actual labels
for i in range(5):
    print(f'Review: {test_df["review_text"].iloc[i]}')
    print(f'Actual Label: {test_df["label"].iloc[i]}, Predicted Score: {predictions[i][0]:.4f}')
    print('Predicted Label:', 'Positive' if predictions[i][0] > 0.5 else 'Negative')
    print('-' * 50)

from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Convert predicted probabilities to binary labels
predicted_labels = np.where(predictions > 0.5, 1, 0)

# Generate confusion matrix
cm = confusion_matrix(test_labels, predicted_labels)

print('Confusion Matrix:')
print(cm)

# Classification Report
print('\nClassification Report:')
print(classification_report(test_labels, predicted_labels, target_names=['Negative', 'Positive']))

# Plot training & validation accuracy values
plt.plot(history['accuracy'], label='Training accuracy')
plt.plot(history['val_accuracy'], label='Validation accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history['loss'], label='Training loss')
plt.plot(history['val_loss'], label='Validation loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()

from sklearn.metrics import roc_curve

# Compute the false positive rate, true positive rate
fpr, tpr, _ = roc_curve(test_labels, predictions)

# Plot the ROC curve
plt.plot(fpr, tpr, label='ROC curve')
plt.plot([0, 1], [0, 1], 'k--')  # Random guessing line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score

# Calculate AUC
auc = roc_auc_score(test_labels, predictions)
print(f'AUC score: {auc:.4f}')

